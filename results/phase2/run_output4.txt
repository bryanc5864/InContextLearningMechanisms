2026-01-28 00:12:05,178 [INFO] Phase 2: Representation Localization
2026-01-28 00:12:05,178 [INFO] Start: 2026-01-28T00:12:05.178771
2026-01-28 00:12:05,178 [INFO] Tasks: ['uppercase', 'first_letter', 'repeat_word', 'length', 'linear_2x', 'sentiment', 'antonym', 'pattern_completion']
2026-01-28 00:12:05,178 [INFO] Positions: ['last_demo_token', 'separator_after_demo', 'first_query_token']
Loading meta-llama/Llama-3.2-3B-Instruct...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.87s/it]
2026-01-28 00:12:29,308 [INFO] Model: {'name': 'meta-llama/Llama-3.2-3B-Instruct', 'n_layers': 28, 'd_model': 3072, 'n_heads': 24, 'vocab_size': 128256, 'device': 'cuda:3'}
2026-01-28 00:12:29,309 [INFO] ============================================================
2026-01-28 00:12:29,309 [INFO] Step 1: Extracting activations
2026-01-28 00:12:29,309 [INFO] ============================================================
2026-01-28 00:12:29,309 [INFO] Loading cached activations from results/phase2/activations_cache.pkl
2026-01-28 00:12:51,419 [INFO] Loaded. 400 samples per position.
2026-01-28 00:12:51,425 [INFO] ============================================================
2026-01-28 00:12:51,430 [INFO] Step 2: Training linear probes
2026-01-28 00:12:51,430 [INFO] ============================================================
2026-01-28 00:12:51,430 [INFO] 
--- Position: last_demo_token ---
2026-01-28 00:14:38,720 [INFO]   Layer  0: 1.000 +/- 0.000
2026-01-28 00:22:17,408 [INFO]   Layer  4: 1.000 +/- 0.000
