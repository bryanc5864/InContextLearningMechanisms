2026-01-28 00:00:55,868 [INFO] Phase 2: Representation Localization
2026-01-28 00:00:55,868 [INFO] Start: 2026-01-28T00:00:55.868599
2026-01-28 00:00:55,868 [INFO] Tasks: ['uppercase', 'first_letter', 'repeat_word', 'length', 'linear_2x', 'sentiment', 'antonym', 'pattern_completion']
2026-01-28 00:00:55,868 [INFO] Positions: ['last_demo_token', 'separator_after_demo', 'first_query_token']
Loading meta-llama/Llama-3.2-3B-Instruct...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.72s/it]
2026-01-28 00:01:14,750 [INFO] Model: {'name': 'meta-llama/Llama-3.2-3B-Instruct', 'n_layers': 28, 'd_model': 3072, 'n_heads': 24, 'vocab_size': 128256, 'device': 'cuda:3'}
2026-01-28 00:01:14,750 [INFO] ============================================================
2026-01-28 00:01:14,751 [INFO] Step 1: Extracting activations
2026-01-28 00:01:14,751 [INFO] ============================================================
2026-01-28 00:01:14,751 [INFO] Loading cached activations from results/phase2/activations_cache.pkl
2026-01-28 00:01:38,539 [INFO] Loaded. 400 samples per position.
2026-01-28 00:01:38,545 [INFO] ============================================================
2026-01-28 00:01:38,548 [INFO] Step 2: Training linear probes
2026-01-28 00:01:38,549 [INFO] ============================================================
2026-01-28 00:01:38,549 [INFO] 
--- Position: last_demo_token ---
2026-01-28 00:04:20,600 [INFO]   Layer  0: 1.000 +/- 0.000
